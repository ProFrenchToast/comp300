{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook will be used to show the performance of the first attempt at learning reward.\n",
    "\n",
    "first load the trained reward network anbd setup methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from baselines.common.vec_env import VecFrameStack\n",
    "from LearningModel.AgentClasses import *\n",
    "from baselines.common.cmd_util import make_vec_env\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2020-02-21-13-08-02-775927\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/common/misc_util.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/common/tf_util.py:53: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/common/tf_util.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/common/tf_util.py:70: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/ppo2/model.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/common/policies.py:43: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdfa9c11668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fdf8c4f5ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/baselines-master/baselines/ppo2/model.py:100: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/patrick/PycharmProjects/comp300/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load the reward network\n",
    "trainedNetwork = RewardNetwork(\"\")\n",
    "\n",
    "trainedNetwork.load_state_dict(torch.load(\"/home/patrick/models/fullGuiTest/fullTest.params\"))\n",
    "\n",
    "#setup the env\n",
    "model_path = \"/home/patrick/models/BreakoutNoFrameskip-v4-groundTruth\"\n",
    "env_id = 'BreakoutNoFrameskip-v4'\n",
    "env_type = 'atari'\n",
    "\n",
    "env = make_vec_env(env_id, env_type, 1, 0,\n",
    "                   wrapper_kwargs={\n",
    "                       'clip_rewards': False,\n",
    "                       'episode_life': False,\n",
    "                   })\n",
    "env = VecFrameStack(env, 4)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = PPO2Agent(env, 'atari', True)\n",
    "trainedNetwork.to(device)\n",
    "\n",
    "#run the agent in the env once and save the ground truth reward and observations\n",
    "def GetDemoFromAgent(agent, network, env):\n",
    "    trueReward = 0\n",
    "    learnedReward = 0\n",
    "\n",
    "    currentReward = 0\n",
    "    currentObservation = env.reset()\n",
    "    timeSteps = 0\n",
    "    done = False\n",
    "\n",
    "    #run the demo\n",
    "    while True:\n",
    "        trueReward += currentReward\n",
    "        shapedObservation = torch.from_numpy(currentObservation).float().to(device)\n",
    "        reward, abs_reward = network.predict_reward(shapedObservation)\n",
    "        learnedReward += reward.tolist()\n",
    "\n",
    "        action = agent.act(currentObservation,  currentReward, done)\n",
    "        currentObservation, currentReward, done, info = env.step(action)\n",
    "        shapedObservations = currentObservation\n",
    "        timeSteps += 1\n",
    "\n",
    "        if done:\n",
    "            trueReward += currentReward\n",
    "            reward, abs_reward = network.predict_reward(shapedObservation)\n",
    "            learnedReward += reward.tolist()\n",
    "            break\n",
    "    print(\"{}, {}\".format(trueReward, learnedReward))\n",
    "    return trueReward, learnedReward\n",
    "\n",
    "#a method to find all the models in a given dir that are just numbers\n",
    "def Find_all_Models(model_dir):\n",
    "\n",
    "    checkpoints = []\n",
    "    filesandDirs = listdir(model_dir)\n",
    "    allFiles = []\n",
    "    for i in filesandDirs:\n",
    "        if isfile(join(model_dir, i)):\n",
    "            allFiles.append(i)\n",
    "\n",
    "    for file in allFiles:\n",
    "        if re.match('^[0-9]+$',file.title()):\n",
    "            checkpoints.append(file.title())\n",
    "\n",
    "    return checkpoints\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now load all models and run each to get demos to run the network on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.], 5807.086614608765\n",
      "[99.], 8801.28234577179\n",
      "[302.], 9686.289559841156\n",
      "[279.], 12355.746445178986\n",
      "[315.], 10104.987102985382\n",
      "[311.], 11991.43548154831\n",
      "[121.], 9723.304317951202\n",
      "[353.], 12904.598839759827\n",
      "[262.], 10444.717190265656\n",
      "[35.], 5633.167418003082\n",
      "[249.], 8418.554112315178\n",
      "[324.], 9844.46140730381\n",
      "[391.], 10147.289002656937\n",
      "[198.], 8974.429542779922\n",
      "[78.], 8364.966038703918\n",
      "[272.], 12268.841401815414\n",
      "[326.], 12195.57649922371\n",
      "[338.], 10841.334688067436\n",
      "[16.], 4279.92800617218\n",
      "[346.], 7174.848008517176\n",
      "[278.], 9919.384356021881\n",
      "[87.], 7814.639692306519\n",
      "[63.], 7264.450046539307\n",
      "[356.], 13221.490128993988\n",
      "[339.], 10248.476876974106\n",
      "[268.], 9209.965847492218\n",
      "[378.], 8443.879289865494\n",
      "[38.], 6081.103522777557\n",
      "[308.], 9138.051247358322\n",
      "[284.], 8621.057996749878\n",
      "[313.], 9617.301353931427\n",
      "[299.], 7828.881627559662\n",
      "[321.], 10725.391894340515\n",
      "[302.], 10865.210080623627\n",
      "[348.], 10141.492789268494\n",
      "[159.], 9988.903798103333\n",
      "[298.], 9585.462687969208\n",
      "[268.], 10379.92119550705\n",
      "[279.], 8057.151013493538\n",
      "[310.], 11714.260393619537\n",
      "[248.], 11539.688991069794\n",
      "[397.], 9789.16431593895\n",
      "[230.], 7727.391618620604\n",
      "[322.], 13280.667091846466\n",
      "[71.], 6984.739717006683\n",
      "[346.], 10440.328704416752\n",
      "[277.], 9502.435929775238\n",
      "[313.], 7459.110349774361\n",
      "[208.], 9717.751136779785\n",
      "[378.], 12107.861311793327\n",
      "[365.], 7344.424700513482\n",
      "[300.], 9236.152712345123\n",
      "[349.], 9564.570273399353\n",
      "[355.], 9457.291243195534\n",
      "[304.], 11160.770686149597\n",
      "[319.], 11076.236113071442\n",
      "[274.], 8075.824638646096\n",
      "[353.], 12210.15179347992\n",
      "[29.], 4659.289335727692\n",
      "[215.], 8305.430452823639\n",
      "[118.], 9312.151612758636\n",
      "[345.], 9565.281010627747\n",
      "[90.], 6966.141745328903\n",
      "[390.], 12259.02703332901\n",
      "[216.], 10559.757917404175\n",
      "[367.], 9142.257466316223\n",
      "[333.], 9067.13308084011\n",
      "[64.], 6067.321312904358\n",
      "[301.], 6959.217396736145\n",
      "[280.], 8233.289855957031\n",
      "[289.], 8930.11586523056\n",
      "[351.], 12876.726349473\n",
      "[345.], 10133.908865451813\n",
      "[23.], 5811.2001004219055\n",
      "[316.], 11484.64032459259\n",
      "[302.], 7089.7847316637635\n",
      "[310.], 10787.763614177704\n",
      "[63.], 4736.97137260437\n",
      "[271.], 11078.745413780212\n",
      "[330.], 9302.33416044712\n",
      "[60.], 8892.586020469666\n",
      "[291.], 10551.57743692398\n",
      "[316.], 10996.867453813553\n",
      "[110.], 7149.44607591629\n",
      "[275.], 8409.896935462952\n",
      "[282.], 7184.181681632996\n",
      "[314.], 10429.213363170624\n",
      "[282.], 12667.623648643494\n",
      "[46.], 6300.432435035706\n",
      "[101.], 8570.969338178635\n",
      "[317.], 13680.843649625778\n",
      "[360.], 8538.947511702776\n",
      "[112.], 9376.011679172516\n",
      "[300.], 8286.183456897736\n",
      "[370.], 10458.962168097496\n",
      "[338.], 10954.831430912018\n",
      "[192.], 9455.513098955154\n",
      "[102.], 7431.82351398468\n",
      "[269.], 8837.945419549942\n",
      "[46.], 6196.799528121948\n",
      "[317.], 9441.033558607101\n",
      "[37.], 6260.134233951569\n",
      "[327.], 10874.143354654312\n",
      "[59.], 8465.740351200104\n",
      "[305.], 11582.025768756866\n",
      "[108.], 9176.21011853218\n",
      "[295.], 10956.516231060028\n",
      "[346.], 8546.410547852516\n",
      "[29.], 4555.707805633545\n",
      "[315.], 9152.690932035446\n",
      "[305.], 10159.593875288963\n",
      "[313.], 8307.951759815216\n",
      "[309.], 8547.908637944609\n",
      "[315.], 12342.864748001099\n",
      "[282.], 7060.381901025772\n",
      "[322.], 9285.41620220989\n",
      "[319.], 11088.804913043976\n",
      "[119.], 7840.4800589084625\n",
      "[210.], 5700.7648490816355\n",
      "[281.], 8549.869417190552\n",
      "[269.], 9489.108108520508\n",
      "[278.], 11363.168637752533\n",
      "[343.], 9028.332923710346\n",
      "[313.], 10641.096229791641\n",
      "[280.], 8552.686206102371\n",
      "[88.], 6906.8791670799255\n",
      "[381.], 11149.603763341904\n",
      "[37.], 6257.989608764648\n",
      "[103.], 8712.609487056732\n",
      "[223.], 6594.908525943756\n",
      "[253.], 10141.349753856659\n",
      "[374.], 11646.108250021935\n",
      "[291.], 10844.201611757278\n",
      "[296.], 10283.765961647034\n",
      "[370.], 10371.624139763415\n",
      "[322.], 10965.520336866379\n",
      "[300.], 7091.218252778053\n",
      "[140.], 9129.937818050385\n",
      "[139.], 10993.72313451767\n",
      "[344.], 10406.119448423386\n",
      "[297.], 8744.987915992737\n",
      "[315.], 10229.499846220016\n",
      "[272.], 11496.494458913803\n",
      "[115.], 7931.678883552551\n",
      "[250.], 11142.079451084137\n",
      "[287.], 10082.93005657196\n",
      "[269.], 7681.250134944916\n",
      "[360.], 10118.684303164482\n",
      "[65.], 8804.853709220886\n",
      "[82.], 6033.116935253143\n",
      "[269.], 10217.384113788605\n",
      "[296.], 8248.281212806702\n",
      "[327.], 6859.058267131448\n",
      "[307.], 9619.239707708359\n",
      "[379.], 12284.98649930954\n",
      "[296.], 8264.901323080063\n",
      "[42.], 6531.022221088409\n",
      "[51.], 8603.726284503937\n",
      "[71.], 7989.960733890533\n",
      "[328.], 8859.884840726852\n",
      "[303.], 9391.07638335228\n",
      "[292.], 9281.159168243408\n",
      "[300.], 8319.57774233818\n",
      "[34.], 5985.670094013214\n",
      "[41.], 5742.808310031891\n",
      "[302.], 11911.97749531269\n",
      "[190.], 10415.94198858738\n",
      "[305.], 8081.250623717904\n",
      "[321.], 12695.018649578094\n",
      "[317.], 10338.360233068466\n",
      "[85.], 9769.043723106384\n",
      "[332.], 24646.700173974037\n",
      "[96.], 9329.0840716362\n",
      "[51.], 3904.3856687545776\n",
      "[350.], 10317.549858570099\n",
      "[110.], 8304.543948888779\n",
      "[318.], 11056.445557117462\n",
      "[399.], 11400.369902133942\n",
      "[333.], 10022.50634431839\n",
      "[150.], 9937.816843509674\n",
      "[320.], 11154.530833244324\n",
      "[313.], 9213.015622138977\n",
      "[20.], 3232.468406677246\n",
      "[63.], 7684.548876285553\n",
      "[325.], 9295.630119562149\n",
      "[253.], 9052.293167948723\n",
      "[383.], 9270.492461442947\n",
      "[52.], 6719.260636329651\n",
      "[100.], 8795.257219314575\n",
      "[326.], 6482.360709596425\n",
      "[27.], 4279.770519733429\n",
      "[78.], 8747.80739068985\n",
      "[300.], 10585.801573038101\n",
      "[272.], 9174.093783140182\n",
      "[96.], 6138.405299663544\n",
      "[224.], 11081.376986265182\n",
      "[309.], 11264.358159303665\n",
      "[342.], 11875.540477514267\n",
      "[57.], 6460.101966381073\n",
      "[105.], 7036.1156005859375\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9c7d1e1ea857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmaxTrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueRewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mminLearned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearnedRewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmaxLearned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearnedRewards\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminLearned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mnormalisedRewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearnedRewards\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminLearned\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxLearned\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmaxTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "trueRewards = []\n",
    "learnedRewards = []\n",
    "\n",
    "models = Find_all_Models(model_path)\n",
    "\n",
    "for model in models:\n",
    "    agent.load(model_path + \"/\" + model)\n",
    "    trueReward, learnedReward = GetDemoFromAgent(agent, trainedNetwork, env)\n",
    "    tf.keras.backend.clear_session()\n",
    "    trueRewards.append(trueReward[0])\n",
    "    learnedRewards.append(learnedReward)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTrue = max(trueRewards)\n",
    "minLearned = min(learnedRewards)\n",
    "normalisedRewards = [x-minLearned for x in learnedRewards]\n",
    "copyLearned = []\n",
    "copyTrue = []\n",
    "for i in range(len(normalisedRewards)):\n",
    "    if normalisedRewards[i] < 20000:\n",
    "        pass\n",
    "    else:\n",
    "        copyLearned.append(normalisedRewards[i])\n",
    "        copyTrue.append(trueReward[i])\n",
    "maxLearned = max(copyLearned)\n",
    "copyLearned = (copyLearned) / (maxLearned / maxTrue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399.0,1504.502965927124\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7d6e452f3645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrueRewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalisedRewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learned reward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/comp300/venv/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2847\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2848\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/comp300/venv/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/comp300/venv/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQoAAAOvCAYAAACEXPk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdT4hd9d2A8efGkW7S4CYhITfXoNNAStESCEiUUnXhpp2CKaWLUGcRMxbBxWwUwYUb6WrcuHCEEpDQboxIkK5KRVQoJNC/acEEGu9MjY3gIgSpOnq7KASC2k7MnTdv6OcDZ3HhO4fv2T6cM7/BZDKZBAAAAAD8T9t0vRcAAAAAAK4/oRAAAAAAEAoBAAAAAKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAoHWGwscee6zdu3c3GAz6/e9//6VzP//5z/vGN77R7bff3sMPP9wnn3wytUUBAAAAgI2zrlD4wx/+sDfffLNbb731S2f+9re/9dRTT/XGG2909uzZ/vGPf/TCCy9MbVEAAAAAYOOsKxR+5zvfaTgc/seZl156qbm5ubZv395gMOiRRx7pl7/85VSWBAAAAAA21sy0bjQej69443D37t2Nx+MvnV9aWmppaeny7/fee6/t27dPax0AAAAA+J/y/vvv99FHH33lv59aKLxai4uLLS4uXv49HA5bXV29XusAAAAAwA3tv30R/N9M7dTj0WjUO++8c/n3uXPnGo1G07o9AAAAALCBphYKDx482IkTJ3rvvfeaTCY9//zz/fjHP57W7QEAAACADbSuULiwsHD50+AHHnig2dnZqg4fPtyJEyequu2223r66ae7++67m52dbevWrS0sLGzc5gAAAADA1Awmk8nkei9R/kchAAAAAFyLa+1rU/v0GAAAAAC4cQmFAAAAAIBQCAAAAAAIhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAVxEKz5w504EDB9qzZ0/79+/v9OnTn5v57LPPWlxc7Jvf/GZ33HFH9957b2fPnp3qwgAAAADA9K07FC4sLHTkyJHefvvtHn/88ebn5z83c+LEid56663+8Ic/9Mc//rH777+/J598cpr7AgAAAAAbYF2h8MKFC506dapDhw5VdfDgwVZWVj73tuBgMOijjz7qn//8Z5PJpIsXLzYcDqe/NQAAAAAwVTPrGVpZWWnHjh3NzPx7fDAYNBqNGo/Hzc7OXp77/ve/32uvvdb27dv7+te/3s6dO3v99de/8J5LS0stLS1d/n3p0qVreQ4AAAAA4BpM9TCTU6dO9ec//7m///3vvfvuu91///098sgjXzi7uLjY6urq5Wvz5s3TXAUAAAAAuArrCoW7du3q/Pnzra2tVTWZTBqPx41GoyvmXnzxxe67775uueWWNm3a1EMPPdRrr702/a0BAAAAgKlaVyjctm1b+/bt69ixY1UdP3684XB4xWfHVbfddlu/+c1v+vjjj6t69dVX+9a3vjXllQEAAACAaVvX/yisWl5ebn5+vmeeeaYtW7Z09OjRqg4fPtzc3Fxzc3M9+uij/fWvf+3OO+/s5ptvbvv27T3//PMbtjwAAAAAMB2DyWQyud5LVA2Hw1ZXV6/3GgAAAABwQ7rWvjbVw0wAAAAAgBuTUAgAAAAACIUAAAAAgFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAAHQVofDMmTMdOHCgPXv2tH///k6fPv2Fc3/605/67ne/2969e9u7d28vv/zy1JYFAAAAADbGzHoHFxYWOnLkSPPz87300kvNz8938uTJK2Y+/PDDfvCDH/Tiiy92zz339Omnn/bBBx9MfWkAAAAAYLrW9UbhhQsXOnXqVIcOHarq4MGDraysdPbs2SvmfvGLX3TXXXd1zz33VHXTTTe1devWKa8MAAAAAEzbukLhyspKO3bsaGbm3y8gDgaDRqNR4/H4irm//OUvfe1rX+t73/te3/72t/vJT37S+++/P/2tAQAAAICpmuphJmtra/36179ueXm53/3ud+3cubOf/vSnXzi7tLTUcDi8fF26dGmaqwAAAAAAV2FdoXDXrl2dP3++tbW1qiaTSePxuNFodMXcaDTq3nvvbefOnQ0Ggw4dOtRvf/vbL7zn4uJiq6url6/Nmzdf46MAAAAAAF/VukLhtm3b2rdvX8eOHavq+PHjDYfDZmdnr5j70Y9+1MmTJ7t48WJVv/rVr7rzzjunvDIAAAAAMG3rPvV4eXm5+fn5nnnmmbZs2dLRo0erOnz4cHNzc83NzTUajXryySc7cOBAmzZtaufOnb3wwgsbtjwAAAAAMB2DyWQyud5LVA2Hw1ZXV6/3GgAAAABwQ7rWvjbVw0wAAAAAgBuTUAgAAAAACIUAAAAAgFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAAAJhQAAAABAQiEAAAAAkFAIAAAAACQUAgAAAABdRSg8c+ZMBw4caM+ePe3fv7/Tp09/6exkMum+++7rlltumcqSAAAAAMDGWncoXFhY6MiRI7399ts9/vjjzc/Pf+nss88+2+233z6N/QAAAACA/wPrCoUXLlzo1KlTHTp0qKqDBw+2srLS2bNnPzd7+vTpXnnllZ544onpbgoAAAAAbJh1hcKVlZV27NjRzMxMVYPBoNFo1Hg8vmLuk08+6eGHH255ebmbbrrpP95zaWmp4XB4+bp06dJXfAQAAAAA4FpN9TCTp59+ugcffLC9e/f+19nFxcVWV1cvX5s3b57mKgAAAADAVZhZz9CuXbs6f/58a2trzczMNJlMGo/HjUajK+Zef/31xuNxzz33XGtra128eLHdu3d38uTJtm7duiEPAAAAAABcu3W9Ubht27b27dvXsWPHqjp+/HjD4bDZ2dkr5t54443eeeedzp0715tvvtmWLVs6d+6cSAgAAAAA/8+t+9Pj5eXllpeX27NnTz/72c86evRoVYcPH+7EiRMbtiAAAAAAsPEGk8lkcr2XqBoOh62url7vNQAAAADghnStfW2qh5kAAAAAADcmoRAAAAAAEAoBAAAAAKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAAIKEQAAAAAEgoBAAAAAASCgEAAACAhEIAAAAA+Fd7dxdaBeH/cfyzVPLCJIlsw3kcPix0PUxRSbHQvNmFD9AqvBgloc4gutiFRilYJFgXRnWjhggm6YVKSHVVRmgSqfSkRjpwnplOI4g5IlM8v4v4yV+s/+9MtzOT1wt2cdh38t3F18nbnXOIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAehEKT5w4kZkzZ6a+vj7Tpk3L0aNHr5vZu3dvpk+fnkmTJqWhoSErVqzIlStX+nRhAAAAAKDvlR0KW1tbs2zZshw/fjwrV67M4sWLr5sZMWJEduzYkWPHjuXw4cM5cOBAtm7d2pf7AgAAAAD9oKxQeP78+Rw6dCgtLS1Jkubm5nR2dqa9vf2aucmTJ2fs2LFJkqFDh6axsTEdHR19uzEAAAAA0OfKCoWdnZ2pqanJ4MGDkyRVVVUpFAopFov/+DVdXV3ZuXNn5s2b97efX79+fWpra69+9PT03MD6AAAAAEBf6Jc3M+nu7s78+fOzYsWKTJ069W9n2tracvr06asfw4YN649VAAAAAIAylBUKR48enbNnz+by5ctJklKplGKxmEKhcN3shQsX0tTUlIULF6atra1vtwUAAAAA+kVZoXDkyJGZMmVKtm3bliTZtWtXamtrM378+Gvmenp60tTUlKampqxatarvtwUAAAAA+kXZTz3euHFjNm7cmPr6+qxbty5btmxJkixZsiR79uxJkrz99tv5+uuvs3v37jQ2NqaxsTFr167tn80BAAAAgD5TVSqVSgO9RJLU1tbm9OnTA70GAAAAAPwr3Wxf65c3MwEAAAAA/l2EQgAAAABAKAQAAAAAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAAJE0JVgAAAgmSURBVBEKAQAAAIAIhQAAAABAhEIAAAAAIEIhAAAAABChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQIRCAAAAACBCIQAAAAAQoRAAAAAAiFAIAAAAAEQoBAAAAAAiFAIAAAAAEQoBAAAAgAiFAAAAAECEQgAAAAAgQiEAAAAAEKEQAAAAAIhQCAAAAABEKAQAAAAAIhQCAAAAABEKAQAAAIAIhQAAAABAhEIAAAAAIL0IhSdOnMjMmTNTX1+fadOm5ejRo387t3nz5kyYMCHjxo3L0qVLc+nSpT5bFgAAAADoH2WHwtbW1ixbtizHjx/PypUrs3jx4utmTp48mdWrV2ffvn1pb2/PuXPnsmnTpr7cFwAAAADoB2WFwvPnz+fQoUNpaWlJkjQ3N6ezszPt7e3XzO3cuTMLFixIdXV1qqqqsnz58mzfvr3vtwYAAAAA+tTgcoY6OztTU1OTwYP/Gq+qqkqhUEixWMz48eOvzhWLxYwZM+bq47q6uhSLxb/9M9evX5/169dffXzmzJnU1tbe0DcB3Np6enoybNiwgV4D6AfuG25f7htuX+4bbl9dXV039fVlhcL+0NbWlra2tquPa2trc/r06YFaB+hH7htuX+4bbl/uG25f7htuXzf7S3hlPfV49OjROXv2bC5fvpwkKZVKKRaLKRQK18wVCoWcOnXq6uOOjo7rZgAAAACAW09ZoXDkyJGZMmVKtm3bliTZtWtXamtrr3nacfLXaxfu2bMnXV1dKZVK2bBhQxYtWtT3WwMAAAAAfWrQmjVr1pQzOGPGjKxevTpvvvlmDh48mC1btuS+++7LkiVLkiT3339/RowYkeHDh+e5557LO++8k4aGhqxZsyaDBg0qa5kZM2bc8DcC3NrcN9y+3Dfcvtw33L7cN9y+bua+q0qlUqkPdwEAAAAA/oXKeuoxAAAAAHB7EwoBAAAAAKEQAAAAAKhgKDxx4kRmzpyZ+vr6TJs2LUePHv3buc2bN2fChAkZN25cli5dmkuXLlVqReAGlXPfe/fuzfTp0zNp0qQ0NDRkxYoVuXLlygBsC/RGuT+/k6RUKuXxxx/P3XffXcENgRtV7n3/8MMPmT17diZOnJiJEydm9+7dFd4U6K1y7vvKlStpa2vLpEmT8tBDD2XOnDlpb28fgG2B3njxxRdTV1eXqqqqfPvtt/84d6N9rWKhsLW1NcuWLcvx48ezcuXKLF68+LqZkydPZvXq1dm3b1/a29tz7ty5bNq0qVIrAjeonPseMWJEduzYkWPHjuXw4cM5cOBAtm7dWvllgV4p577/66233sq4ceMqtxxwU8q5799//z0LFy7M66+/nh9//DFHjhzJo48+WvllgV4p57737NmTL7/8Mt99912+//77zJ07Ny+//HLllwV65cknn8z+/fszZsyYf5y5mb5WkVB4/vz5HDp0KC0tLUmS5ubmdHZ2Xve/FTt37syCBQtSXV2dqqqqLF++PNu3b6/EisANKve+J0+enLFjxyZJhg4dmsbGxnR0dFR6XaAXyr3vJDl69Gg+/PDDvPTSS5VeE7gB5d73Bx98kEceeSSzZs1KkgwaNCj33ntvxfcFylfufVdVVeXixYv5448/UiqV0t3dndra2oFYGeiFxx577H/e6s30tYqEws7OztTU1GTw4MFJ/voLqVAopFgsXjNXLBavKaJ1dXXXzQC3lnLv+//q6urKzp07M2/evEqtCdyAcu/70qVLWbp0aTZu3JhBgwYNxKpAL5V738eOHcudd96ZefPmpbGxMc8880x++eWXgVgZKFO59z1//vzMnj071dXVqampyWeffZbXXnttIFYG+tjN9DVvZgJUVHd3d+bPn58VK1Zk6tSpA70O0AdeffXVPPHEE5k4ceJArwL0scuXL+fTTz/Nxo0b880332TUqFF5/vnnB3otoA8cOnQoR44cyc8//5wzZ85k7ty5Wb58+UCvBQywioTC0aNH5+zZs7l8+XKSv17svFgsplAoXDNXKBRy6tSpq487OjqumwFuLeXed5JcuHAhTU1NWbhwYdra2iq9KtBL5d73F198kXfffTd1dXWZNWtWuru7U1dX57eO4BbWm3+fz5kzJ6NGjUpVVVVaWlry1VdfDcTKQJnKve+tW7defROyO+64I88++2w+//zzgVgZ6GM309cqEgpHjhyZKVOmZNu2bUmSXbt2pba2NuPHj79mrrm5OXv27ElXV1dKpVI2bNiQRYsWVWJF4AaVe989PT1pampKU1NTVq1aNRCrAr1U7n3v27cvp06dSkdHR/bv35/hw4eno6PD65jBLazc+3766adz8ODBdHd3J0k++eSTPPzwwxXfFyhfufc9duzY7N27N3/++WeS5KOPPsoDDzxQ8X2Bvnczfa2qVCqV+nm/JMlPP/2UxYsX59dff83w4cOzZcuWPPjgg1myZEkWLFiQBQsWJEnee++9rFu3Lkkye/bsbNiwIUOGDKnEisANKue+165dmzVr1qShoeHq1z311FN55ZVXBnBz4H8p9+f3f3V0dKSxsTG//fbbAG0MlKvc+37//ffzxhtv5I477sioUaOyadOmjB49eoC3B/4/5dz3xYsX88ILL2T//v0ZMmRIqqurs2HDhqtvQAjcmlpbW/Pxxx+nq6sr99xzT+666660t7f3WV+rWCgEAAAAAG5d3swEAAAAABAKAQAAAAChEAAAAACIUAgAAAAARCgEAAAAACIUAgAAAAARCgEAAACACIUAAAAAQJL/ACcvCsgT3gm6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1600x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "print(\"{},{}\".format(maxTrue, maxLearned))\n",
    "\n",
    "figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.scatter(np.array(trueRewards), np.array(normalisedRewards), c='r')\n",
    "plt.plot(np.arange(500), np.arange(500))\n",
    "plt.ylabel(\"Learned reward\")\n",
    "plt.xlabel(\"Ground truth reward\")\n",
    "plt.title(\"graph of learned reward against ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minReward = [min(trueRewards)]\n",
    "maxReward = [max(trueRewards)]\n",
    "average = [sum(trueRewards) / len(trueRewards)]\n",
    "\n",
    "from LearningModel.getAverageReward import *\n",
    "agent.load(\"~/models/breakout-reward-RL/breakout_50M_ppo2\")\n",
    "meanR, minR,maxR, std = getAvgReward(agent, env, 200)\n",
    "\n",
    "minReward.append(minR)\n",
    "maxReward.append(maxR)\n",
    "average.append(meanR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minReward[0] = min(trueRewards)\n",
    "maxReward[0] = max(trueRewards)\n",
    "average[0] = sum(trueRewards) /len(trueRewards)\n",
    "print(\"mins: {}, maxs: {}, means: {}\".format(minReward, maxReward, average))\n",
    "# create plot\n",
    "figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "#fig, ax = plt.subplots()\n",
    "index = np.arange(2)\n",
    "bar_width = 0.3\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, minReward, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='Minimum Reward')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, average, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Average Reward')\n",
    "\n",
    "rects3 = plt.bar(index + bar_width +bar_width, maxReward, bar_width,\n",
    "alpha=opacity,\n",
    "color='r',\n",
    "label='Max Reward')\n",
    "\n",
    "plt.xlabel('Agent')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('The min, max and mean reward of the demonstrator and trained agent')\n",
    "plt.xticks(index + bar_width, ('Demonstrations', 'Trained agent'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
